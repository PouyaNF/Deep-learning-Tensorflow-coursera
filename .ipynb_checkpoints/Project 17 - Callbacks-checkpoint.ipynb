{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f819786",
   "metadata": {},
   "source": [
    "# Introduction to Keras callbacks\n",
    "\n",
    "In Keras, `Callback` is a Python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training. The methods of the callbacks can  be called at different stages of training/evaluating/inference. Keras has available [callbacks](https://keras.io/api/callbacks/) and we'll show how you can use it in the following sections. Please click the **Open in Colab** badge above to complete this exercise in Colab. This will allow you to take advantage of the free GPU runtime (for faster training) and compatibility with all the packages needed in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439a0b6",
   "metadata": {},
   "source": [
    "## Model methods that take callbacks\n",
    "Users can supply a list of callbacks to the following `tf.keras.Model` methods:\n",
    "* [`fit()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit), [`fit_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator)\n",
    "Trains the model for a fixed number of epochs (iterations over a dataset, or data yielded batch-by-batch by a Python generator).\n",
    "* [`evaluate()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate), [`evaluate_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate_generator)\n",
    "Evaluates the model for given data or data generator. Outputs the loss and metric values from the evaluation.\n",
    "* [`predict()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict), [`predict_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict_generator)\n",
    "Generates output predictions for the input data or data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb223d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# Video(\"Project 17 - Custom Callbacks.webm\",  embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc29579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Version:  2.9.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021166c",
   "metadata": {},
   "source": [
    "# Examples of Built-in Keras callback applications\n",
    "The following section will guide you through creating simple [Callback](https://keras.io/api/callbacks/) applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f9dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\pooya\\tensorflow_datasets\\horses_or_humans\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddc4b6e23164069971bb0ce11b38e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcc09f8582d42eaab719a72816ae1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling horses_or_humans-train.tfrecord...:   0%|          | 0/1027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling horses_or_humans-test.tfrecord...:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset horses_or_humans downloaded and prepared to C:\\Users\\pooya\\tensorflow_datasets\\horses_or_humans\\3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare the horses or humans dataset\n",
    "\n",
    "splits, info = tfds.load('horses_or_humans', as_supervised = True, with_info=True, split=['train[:80%]', 'train[80%:]', 'test'])\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a23824",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 150 #@param {type:\"slider\", min:64, max:300, step:1}\n",
    "IMAGE_SIZE = (SIZE, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81156b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "  return  image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee46454",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a34b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448ced6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 150, 150, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "  pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5976f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dense_units, input_shape=IMAGE_SIZE + (3,)):\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(dense_units, activation='relu'),\n",
    "      tf.keras.layers.Dense(2, activation='softmax')\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac7cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d775ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 10s 244ms/step - loss: 0.6809 - accuracy: 0.5449 - val_loss: 0.6542 - val_accuracy: 0.5561\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6249 - accuracy: 0.6617 - val_loss: 0.5857 - val_accuracy: 0.8244\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.5713 - accuracy: 0.7398 - val_loss: 0.5038 - val_accuracy: 0.8146\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.4982 - accuracy: 0.7944 - val_loss: 0.4460 - val_accuracy: 0.8341\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.3947 - accuracy: 0.8406 - val_loss: 0.3480 - val_accuracy: 0.8829\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.3752 - accuracy: 0.8650 - val_loss: 0.2817 - val_accuracy: 0.9073\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.3238 - accuracy: 0.8938 - val_loss: 0.2430 - val_accuracy: 0.9171\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.2625 - accuracy: 0.9145 - val_loss: 0.2015 - val_accuracy: 0.9463\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.2195 - accuracy: 0.9233 - val_loss: 0.3329 - val_accuracy: 0.8341\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.2209 - accuracy: 0.9180 - val_loss: 0.1529 - val_accuracy: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155806ceba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=10, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68c4e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c371892dfce44969\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c371892dfce44969\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9981e81",
   "metadata": {},
   "source": [
    "## [Model Checkpoint](https://keras.io/api/callbacks/model_checkpoint/)\n",
    "\n",
    "Callback to save the Keras model or model weights at some frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7ff11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 - 4s - loss: 0.6711 - accuracy: 0.5827 - val_loss: 0.6493 - val_accuracy: 0.7463\n",
      "\n",
      "Epoch 00001: saving model to weights.01-0.65.h5\n",
      "Epoch 2/5\n",
      "26/26 - 4s - loss: 0.6260 - accuracy: 0.6898 - val_loss: 0.6465 - val_accuracy: 0.5805\n",
      "\n",
      "Epoch 00002: saving model to weights.02-0.65.h5\n",
      "Epoch 3/5\n",
      "26/26 - 4s - loss: 0.5968 - accuracy: 0.6898 - val_loss: 0.6506 - val_accuracy: 0.5463\n",
      "\n",
      "Epoch 00003: saving model to weights.03-0.65.h5\n",
      "Epoch 4/5\n",
      "26/26 - 4s - loss: 0.5876 - accuracy: 0.7032 - val_loss: 0.5219 - val_accuracy: 0.8293\n",
      "\n",
      "Epoch 00004: saving model to weights.04-0.52.h5\n",
      "Epoch 5/5\n",
      "26/26 - 4s - loss: 0.5070 - accuracy: 0.7822 - val_loss: 0.4972 - val_accuracy: 0.7951\n",
      "\n",
      "Epoch 00005: saving model to weights.05-0.50.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15589b8e668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.h5', verbose=1),\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592f336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 4s - loss: 0.6712 - accuracy: 0.5815 - val_loss: 0.7149 - val_accuracy: 0.4488\n",
      "\n",
      "Epoch 00001: saving model to saved_model\n",
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1558a713ba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=1, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('saved_model', verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=2, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('model.h5', verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928b595",
   "metadata": {},
   "source": [
    "## [Early stopping](https://keras.io/api/callbacks/early_stopping/)\n",
    "\n",
    "Stop training when a monitored metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=50, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[EarlyStopping(\n",
    "              patience=3,\n",
    "              min_delta=0.05,\n",
    "              baseline=0.8,\n",
    "              mode='min',\n",
    "              monitor='val_loss',\n",
    "              restore_best_weights=True,\n",
    "              verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb284b3",
   "metadata": {},
   "source": [
    "## [CSV Logger](https://keras.io/api/callbacks/csv_logger/)\n",
    "\n",
    "Callback that streams epoch results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58fc56c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.6795 - accuracy: 0.5841 - val_loss: 0.6623 - val_accuracy: 0.5512\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.6344 - accuracy: 0.6609 - val_loss: 0.6138 - val_accuracy: 0.7024\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.5818 - accuracy: 0.7544 - val_loss: 0.5945 - val_accuracy: 0.6488\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.5184 - accuracy: 0.7509 - val_loss: 0.5128 - val_accuracy: 0.7951\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.4659 - accuracy: 0.7780 - val_loss: 0.4193 - val_accuracy: 0.7951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155d98ab940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "csv_file = 'training.csv'\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[CSVLogger(csv_file)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b088f622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.618005</td>\n",
       "      <td>0.668965</td>\n",
       "      <td>0.551220</td>\n",
       "      <td>0.662288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.681265</td>\n",
       "      <td>0.627584</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.613802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>0.563054</td>\n",
       "      <td>0.648780</td>\n",
       "      <td>0.594503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>0.505214</td>\n",
       "      <td>0.795122</td>\n",
       "      <td>0.512806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.796837</td>\n",
       "      <td>0.451036</td>\n",
       "      <td>0.795122</td>\n",
       "      <td>0.419333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0      0  0.618005  0.668965      0.551220  0.662288\n",
       "1      1  0.681265  0.627584      0.702439  0.613802\n",
       "2      2  0.755474  0.563054      0.648780  0.594503\n",
       "3      3  0.778589  0.505214      0.795122  0.512806\n",
       "4      4  0.796837  0.451036      0.795122  0.419333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(csv_file).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8a242",
   "metadata": {},
   "source": [
    "## [Learning Rate Scheduler](https://keras.io/api/callbacks/learning_rate_scheduler/)\n",
    "\n",
    "Updates the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f6ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.005.\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.6938 - accuracy: 0.5521 - val_loss: 0.7139 - val_accuracy: 0.4341\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0025.\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6471 - accuracy: 0.5986 - val_loss: 0.6318 - val_accuracy: 0.7610\n",
      "Epoch 3/5\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00125.\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6125 - accuracy: 0.7300 - val_loss: 0.6201 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000625.\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6036 - accuracy: 0.7695 - val_loss: 0.6103 - val_accuracy: 0.8098\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0003125.\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.5981 - accuracy: 0.8138 - val_loss: 0.6110 - val_accuracy: 0.7854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155f42ffeb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "def step_decay(epoch):\n",
    "\tinitial_lr = 0.01\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 1\n",
    "\tlr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lr\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[LearningRateScheduler(step_decay, verbose=1),\n",
    "                    TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3476ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3bbfdcd3c26294db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3bbfdcd3c26294db\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad445207",
   "metadata": {},
   "source": [
    "## [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/)\n",
    "\n",
    "Reduce learning rate when a metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e606d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=50, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[ReduceLROnPlateau(monitor='val_loss', \n",
    "                                       factor=0.2, verbose=1, # factor by which the learning rate will be reduced. new_lr = lr * factor. \n",
    "                                       patience=1, min_lr=0.001),\n",
    "                     TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45887ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c33fb1",
   "metadata": {},
   "source": [
    "# Keras custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a17fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPyImage\n",
    "import imageio\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5142598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model to add callbacks to\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(1, activation = 'linear', input_dim = 784))\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9808251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example MNIST data and pre-process it\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242ef97",
   "metadata": {},
   "source": [
    "Now, define a simple custom callback to track the start and end time of every batch of data. During those calls, it prints the index of the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd1852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2b754",
   "metadata": {},
   "source": [
    "Providing a callback to model methods such as `tf.keras.Model.fit()` ensures the methods are called at those stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd958637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: batch 0 begins at 23:57:47.495810\n",
      "Training: batch 0 ends at 23:57:47.843444\n",
      "Training: batch 1 begins at 23:57:47.843444\n",
      "Training: batch 1 ends at 23:57:47.843444\n",
      "Training: batch 2 begins at 23:57:47.843444\n",
      "Training: batch 2 ends at 23:57:47.843444\n",
      "Training: batch 3 begins at 23:57:47.843444\n",
      "Training: batch 3 ends at 23:57:47.843444\n",
      "Training: batch 4 begins at 23:57:47.843444\n",
      "Training: batch 4 ends at 23:57:47.859065\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          steps_per_epoch=5, # when we set this, wetrain the model on steps_per_epoch num of batches not all training set \n",
    "          verbose=0,\n",
    "          callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9c27e",
   "metadata": {},
   "source": [
    "## An overview of callback methods\n",
    "\n",
    "\n",
    "### Common methods for training/testing/predicting\n",
    "For training, testing, and predicting, following methods are provided to be overridden.\n",
    "#### `on_(train|test|predict)_begin(self, logs=None)`\n",
    "Called at the beginning of `fit`/`evaluate`/`predict`.\n",
    "#### `on_(train|test|predict)_end(self, logs=None)`\n",
    "Called at the end of `fit`/`evaluate`/`predict`.\n",
    "#### `on_(train|test|predict)_batch_begin(self, batch, logs=None)`\n",
    "Called right before processing a batch during training/testing/predicting. Within this method, `logs` is a dict with `batch` and `size` available keys, representing the current batch number and the size of the batch.\n",
    "#### `on_(train|test|predict)_batch_end(self, batch, logs=None)`\n",
    "Called at the end of training/testing/predicting a batch. Within this method, `logs` is a dict containing the stateful metrics result.\n",
    "\n",
    "### Training specific methods\n",
    "In addition, for training, following are provided.\n",
    "#### `on_epoch_begin(self, epoch, logs=None)`\n",
    "Called at the beginning of an epoch during training.\n",
    "#### `on_epoch_end(self, epoch, logs=None)`\n",
    "Called at the end of an epoch during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aacbb6",
   "metadata": {},
   "source": [
    "### Usage of `logs` dict\n",
    "The `logs` dict contains the loss value, and all the metrics at the end of a batch or epoch. Example includes the loss and mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17121ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Val/Train loss ratio: 1.85\n",
      "Epoch: 1, Val/Train loss ratio: 0.89\n",
      "Epoch: 2, Val/Train loss ratio: 0.41\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch,logs: \n",
    "    print(\"Epoch: {}, Val/Train loss ratio: {:.2f}\".format(epoch, logs[\"val_loss\"] / logs[\"loss\"]))\n",
    ")\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=64,\n",
    "          epochs=3,\n",
    "          verbose=0,\n",
    "          callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Val/Train loss ratio: 0.44\n",
      "Epoch: 1, Val/Train loss ratio: 0.40\n",
      "Epoch: 2, Val/Train loss ratio: 1.57\n",
      "Stopping training...\n"
     ]
    }
   ],
   "source": [
    "class DetectOverfittingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold=0.7):\n",
    "        super(DetectOverfittingCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(\"Epoch: {}, Val/Train loss ratio: {:.2f}\".format(epoch, ratio))\n",
    "\n",
    "        if ratio > self.threshold:\n",
    "            print(\"Stopping training...\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "              validation_data=(x_test, y_test),\n",
    "              batch_size=64,\n",
    "              epochs=3,\n",
    "              verbose=0,\n",
    "              callbacks=[DetectOverfittingCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a2af3",
   "metadata": {},
   "source": [
    "Similarly, one can provide callbacks in `evaluate()` calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bef56d",
   "metadata": {},
   "source": [
    "## Custom callback to Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f9daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example MNIST data and pre-process it\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b713bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization utilities\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('figure', figsize=(15, 3))\n",
    "\n",
    "def display_digits(inputs, outputs, ground_truth, epoch, n=10):\n",
    "    plt.clf()\n",
    "\n",
    "    plt.yticks([])\n",
    "    plt.grid(None)\n",
    "    inputs = np.reshape(inputs, [n, 28, 28])\n",
    "    inputs = np.swapaxes(inputs, 0, 1)\n",
    "    inputs = np.reshape(inputs, [28, 28*n])\n",
    "    plt.imshow(inputs)\n",
    "    plt.xticks([28*x+14 for x in range(n)], outputs)\n",
    "    for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
    "        if outputs[i] == ground_truth[i]: \n",
    "            t.set_color('green') \n",
    "        else: \n",
    "            t.set_color('red')\n",
    "    plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "GIF_PATH = './animation.gif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, inputs, ground_truth, display_freq=10, n_samples=10):\n",
    "        self.inputs = inputs\n",
    "        self.ground_truth = ground_truth\n",
    "        self.images = []\n",
    "        self.display_freq = display_freq\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Randomly sample data\n",
    "        indexes = np.random.choice(len(self.inputs), size=self.n_samples)\n",
    "        X_test, y_test = self.inputs[indexes], self.ground_truth[indexes]\n",
    "        predictions = np.argmax(self.model.predict(X_test), axis=1)\n",
    "\n",
    "        # Plot the digits\n",
    "        display_digits(X_test, predictions, y_test, epoch, n=self.display_freq)\n",
    "\n",
    "        # Save the figure\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        image = Image.open(buf)\n",
    "        self.images.append(np.array(image))\n",
    "\n",
    "        # Display the digits every 'display_freq' number of epochs\n",
    "        if epoch % self.display_freq == 0:\n",
    "            plt.show()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        imageio.mimsave(GIF_PATH, self.images, fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(32, activation='linear', input_dim=784))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41796833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          verbose=0,\n",
    "          callbacks=[VisCallback(x_test, y_test)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

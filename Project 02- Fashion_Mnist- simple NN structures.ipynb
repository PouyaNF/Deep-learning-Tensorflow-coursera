{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e28de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "from tensorflow import keras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba6cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9072a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images , train_labels) , (test_images , test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18554b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0caa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d997e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(train_images[42], cmap = 'gray' )\n",
    "print(train_labels[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images , test_images = train_images/255.0 , test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698615a",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7ba9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4927 - accuracy: 0.8285\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3764 - accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3360 - accuracy: 0.8781\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3136 - accuracy: 0.8842\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2969 - accuracy: 0.8913\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2811 - accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2694 - accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2577 - accuracy: 0.9042\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2477 - accuracy: 0.9068\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2386 - accuracy: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6efb31c30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images , train_labels) , (test_images , test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images , test_images = train_images/255.0 , test_images/255.0\n",
    "\n",
    "model1 =keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),  # that the first layer in your network should be the same shape as your data\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10 , activation = tf.nn.softmax)   #the number of neurons in the last layer should match the number of classes you are classifying for\n",
    "])\n",
    "\n",
    "model1.compile(optimizer ='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) # optimizer = 'adam'\n",
    "model1.fit(train_images, train_labels, epochs = 10 )   # 32 images in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "526f0ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3500 - accuracy: 0.8795\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "model1.evaluate(test_images , test_labels)\n",
    "# print (type(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc99429",
   "metadata": {},
   "source": [
    "# model 2  - implementing callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecc1f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images , train_labels) , (test_images , test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images , test_images = train_images/255.0 , test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd901e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):   \n",
    "        if(logs.get('accuracy')>0.90):     # with loss :if (logs.get('loss')< 0.4 )\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92d1fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4990 - accuracy: 0.8243\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3733 - accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3364 - accuracy: 0.8772\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3107 - accuracy: 0.8861\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2932 - accuracy: 0.8926\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2797 - accuracy: 0.8957\n",
      "Epoch 7/10\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9006\n",
      "Reached 90% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2664 - accuracy: 0.9006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6c4411e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "\n",
    "model2 =keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10 , activation = tf.nn.softmax)  \n",
    "])\n",
    "model2.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(train_images, train_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8534b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3498 - accuracy: 0.8777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34980159997940063, 0.8776999711990356]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f110f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[7.1720696e-10 1.4901875e-09 4.2235507e-10 1.6956441e-11 3.2817407e-10\n",
      " 1.5863881e-04 1.5779262e-08 2.0858347e-03 2.1209681e-08 9.9775547e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model2.predict(test_images)\n",
    "print(classifications[0])  # It's the probability that this item is each of the 10 classes\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589dd0e2",
   "metadata": {},
   "source": [
    "# model 3 , with 1024 neurons in hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355de67",
   "metadata": {},
   "source": [
    "by adding more Neurons we have to do more calculations, slowing down the process, but in this case they have a good impact -- we do get more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c548930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4705 - accuracy: 0.8302\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.3568 - accuracy: 0.8713\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3207 - accuracy: 0.8817\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2953 - accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2783 - accuracy: 0.8967\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2618 - accuracy: 0.9011\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2490 - accuracy: 0.9066\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.2394 - accuracy: 0.9109\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2276 - accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.2215 - accuracy: 0.9178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6f5bd5300>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model3 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model3.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model3.fit(training_images, training_labels, epochs= 10 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e3598ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3522 - accuracy: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35224753618240356, 0.8845000267028809]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c239ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "[1.2410725e-08 8.5114656e-15 4.2989965e-14 5.1120031e-15 4.0633165e-12\n",
      " 9.2205082e-06 3.2147682e-10 1.0244994e-03 5.3828760e-12 9.9896622e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model3.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd310cf",
   "metadata": {},
   "source": [
    "# model 4 , with 2 hidden layers :512 , 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb25aac",
   "metadata": {},
   "source": [
    "There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d6c344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4674 - accuracy: 0.8296\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.3568 - accuracy: 0.8683\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.3210 - accuracy: 0.8798\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2954 - accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2801 - accuracy: 0.8948\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2634 - accuracy: 0.9014\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2519 - accuracy: 0.9038\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2393 - accuracy: 0.9094\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2284 - accuracy: 0.9134\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2202 - accuracy: 0.9169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d744ad9000>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model4 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model4.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model4.fit(training_images, training_labels, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19965616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3330 - accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3330107033252716, 0.8888999819755554]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a575d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "[2.2271522e-14 1.0758569e-11 3.6507755e-16 1.1050645e-12 1.6646899e-15\n",
      " 8.2251552e-07 6.7519303e-13 8.7732697e-05 4.7902810e-14 9.9991143e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model4.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "286.841px",
    "left": "1026.36px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

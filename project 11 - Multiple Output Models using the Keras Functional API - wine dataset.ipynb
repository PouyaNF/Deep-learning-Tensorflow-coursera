{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZL_6GK8qX35J"
   },
   "source": [
    "\n",
    "\n",
    "# Week 1: Multiple Output Models using the Keras Functional API\n",
    "\n",
    "Welcome to the first programming assignment of the course! Your task will be to use the Keras functional API to train a model to predict two outputs. For this lab, you will use the **[Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)** from the **UCI machine learning repository**. It has separate datasets for red wine and white wine.\n",
    "\n",
    "Normally, the wines are classified into one of the quality ratings specified in the attributes. In this exercise, you will combine the two datasets to predict the wine quality and whether the wine is red or white solely from the attributes. \n",
    "\n",
    "You will model wine quality estimations as a regression problem and wine type detection as a binary classification problem.\n",
    "\n",
    "#### Please complete sections that are marked **(TODO)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obdcD6urYBY9"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8N3pcTQ5oQI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import utils11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQMERzWQYpgm"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "\n",
    "You will now download the dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). \n",
    "\n",
    "### Pre-process the white wine dataset (TODO)\n",
    "You will add a new column named `is_red` in your dataframe to indicate if the wine is white or red. \n",
    "- In the white wine dataset, you will fill the column `is_red` with  zeros (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "2qYAjKXCd4RH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb9f284ba6255170fe04a309a407d72d",
     "grade": false,
     "grade_id": "cell-e5bfa0f152d9a21f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "# URL of the white wine dataset\n",
    "#URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "# load the dataset from the URL\n",
    "#white_df = pd.read_csv(URL, sep=\";\")\n",
    "\n",
    "\n",
    "white_df = pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "\n",
    "white_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3961, 13)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the `is_red` column with zeros.\n",
    "white_df[\"is_red\"] = 0\n",
    "\n",
    "# keep only the first of duplicate items\n",
    "white_df = white_df.drop_duplicates(keep='first')\n",
    "\n",
    "white_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "defe38d6ec58fd31cd67b89e46c4373f",
     "grade": true,
     "grade_id": "cell-30575e713b55fc51",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "# You can click `File -> Open` in the menu above and open the `utils.py` file \n",
    "# in case you want to inspect the unit tests being used for each graded function.\n",
    "\n",
    "utils11.test_white_df(white_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQHK0ohBQRCk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.8\n",
      "9.1\n"
     ]
    }
   ],
   "source": [
    "print(white_df.alcohol[0])\n",
    "print(white_df.alcohol[100])\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# 8.8\n",
    "# 9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the red wine dataset (TODO)\n",
    "- In the red wine dataset, you will fill in the column `is_red` with ones (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "8y3QxKwBed8v",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be72275f78e2c2d0038dde9aa63f8d4f",
     "grade": false,
     "grade_id": "cell-e47a40f306593274",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>is_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  is_red  \n",
       "0      9.4        5       1  \n",
       "1      9.8        5       1  \n",
       "2      9.8        5       1  \n",
       "3      9.8        6       1  \n",
       "5      9.4        5       1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "# URL of the red wine dataset\n",
    "#URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    " \n",
    "# load the dataset from the URL\n",
    "#red_df = pd.read_csv(URL, sep=\";\")\n",
    "\n",
    "\n",
    "red_df = pd.read_csv(\"winequality-red.csv\", sep = \";\")\n",
    "\n",
    "# fill the `is_red` column with ones.\n",
    "red_df[\"is_red\"] = 1\n",
    "\n",
    "# keep only the first of duplicate items\n",
    "red_df = red_df.drop_duplicates(keep = 'first')\n",
    "red_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 13)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8e0c91b0fd668b63ba74a8f2f958b59",
     "grade": true,
     "grade_id": "cell-2a75937adcc0c25b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_red_df(red_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_red_df(red_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsB3LUzNQpo_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4\n",
      "10.2\n"
     ]
    }
   ],
   "source": [
    "print(red_df.alcohol[0])\n",
    "print(red_df.alcohol[100])\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# 9.4\n",
    "# 10.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G8B-NYuM6-f"
   },
   "source": [
    "### Concatenate the datasets\n",
    "\n",
    "Next, concatenate the red and white wine dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpQrOjJbfN3m"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([red_df, white_df], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>is_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.66         0.00             1.8      0.075   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  is_red  \n",
       "0      9.4        5       1  \n",
       "1      9.8        5       1  \n",
       "2      9.8        5       1  \n",
       "3      9.8        6       1  \n",
       "4      9.4        5       1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5320, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Se2dTmThQyjb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4\n",
      "9.5\n"
     ]
    }
   ],
   "source": [
    "print(df.alcohol[0])\n",
    "print(df.alcohol[100])\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# 9.4\n",
    "# 9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx6y3rPpQv4k"
   },
   "outputs": [],
   "source": [
    "# NOTE: In a real-world scenario, you should shuffle the data.\n",
    "# YOU ARE NOT going to do that here because we want to test\n",
    "# with deterministic data. But if you want the code to do it,\n",
    "# it's in the commented line below:\n",
    "\n",
    "#df = df.iloc[np.random.permutation(len(df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EqIcbg5M_n1"
   },
   "source": [
    "This will chart the quality of the wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsvK0-Sgy17C"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['quality'].hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nut1rmYLzf-p"
   },
   "source": [
    "### Imbalanced data \n",
    "You can see from the plot above that the wine quality dataset is imbalanced. \n",
    "- Since there are very few observations with quality equal to 3, 4, 8 and 9, you can drop these observations from your dataset. \n",
    "- You can do this by removing data belonging to all classes except those > 4 and < 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "doH9_-gnf3sz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9ba9fc3a3ca02ccc567be33652b80fe",
     "grade": false,
     "grade_id": "cell-6a3e9db696f6827b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4931, 13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "# get data with wine quality greater than 4 and less than 8\n",
    "df = df[(df['quality'] > 4) & (df['quality'] < 8 )]\n",
    "\n",
    "# reset index and drop the old one\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "281e1d86a4803560ed5892cd7eda4c01",
     "grade": true,
     "grade_id": "cell-aed3da719d4682c7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_df_drop(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_df_drop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNR1iAlMRPXO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.4\n",
      "10.9\n"
     ]
    }
   ],
   "source": [
    "print(df.alcohol[0])\n",
    "print(df.alcohol[100])\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# 9.4\n",
    "# 10.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwhuRpnVRTzG"
   },
   "source": [
    "You can plot again to see the new range of data and quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "857ygzZiLgGg"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['quality'].hist(bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3k0vqSsp84t"
   },
   "source": [
    "### Train Test Split  \n",
    "\n",
    "Next, you can split the datasets into training, test and validation datasets.\n",
    "- The data frame should be split 80:20 into `train` and `test` sets.\n",
    "- The resulting `train` should then be split 80:20 into `train` and `val` sets.\n",
    "- The `train_test_split` parameter `test_size` takes a float value that ranges between 0. and 1, and represents the proportion of the dataset that is allocated to the test set.  The rest of the data is allocated to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "PAVIf2-fgRVY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f5738f4fb51d65adc9a8acbdf2b9970",
     "grade": false,
     "grade_id": "cell-91946cadf745206b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "# Please do not change the random_state parameter. This is needed for grading.\n",
    "\n",
    "# split df into 80:20 train and test sets\n",
    "train, test = train_test_split(df, test_size = 0.2, random_state = 1)\n",
    "                               \n",
    "# split train into 80:20 train and val sets\n",
    "train, val = train_test_split(train, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3155, 13) (789, 13) (987, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape ,val.shape , test.shape   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "57h9LcEzRWpk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42adbe9e66efac7c7a5f8cd73ac92f22",
     "grade": true,
     "grade_id": "cell-64b8b38cd0b965f6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_data_sizes(train.size, test.size, val.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_data_sizes(train.size, test.size, val.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwTNu4KFqG-K"
   },
   "source": [
    "Here's where you can explore the training stats. You can pop the labels 'is_red' and 'quality' from the data as these will be used as the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_afyhhHM6WQ"
   },
   "outputs": [],
   "source": [
    "train_stats = train.describe()\n",
    "#train_stats.pop('is_red')\n",
    "#train_stats.pop('quality')\n",
    "train_stats = train_stats.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahvbYm4fNqSt"
   },
   "source": [
    "Explore the training stats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_gAtPjZ0otF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>7.221616</td>\n",
       "      <td>1.325297</td>\n",
       "      <td>3.80000</td>\n",
       "      <td>6.40000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>7.7000</td>\n",
       "      <td>15.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>0.338929</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.23000</td>\n",
       "      <td>0.29000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1.24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.147970</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.31000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>5.155911</td>\n",
       "      <td>4.639632</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>1.80000</td>\n",
       "      <td>2.80000</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>65.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>0.056976</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.04700</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>30.388590</td>\n",
       "      <td>17.236784</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>131.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>115.062282</td>\n",
       "      <td>56.706617</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>117.00000</td>\n",
       "      <td>156.0000</td>\n",
       "      <td>344.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>0.994633</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.98711</td>\n",
       "      <td>0.99232</td>\n",
       "      <td>0.99481</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>1.03898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>3.223201</td>\n",
       "      <td>0.161272</td>\n",
       "      <td>2.72000</td>\n",
       "      <td>3.11000</td>\n",
       "      <td>3.21000</td>\n",
       "      <td>3.3300</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>0.534051</td>\n",
       "      <td>0.149149</td>\n",
       "      <td>0.22000</td>\n",
       "      <td>0.43000</td>\n",
       "      <td>0.51000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>10.504466</td>\n",
       "      <td>1.154654</td>\n",
       "      <td>8.50000</td>\n",
       "      <td>9.50000</td>\n",
       "      <td>10.30000</td>\n",
       "      <td>11.3000</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>5.813629</td>\n",
       "      <td>0.701121</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_red</th>\n",
       "      <td>3155.0</td>\n",
       "      <td>0.255784</td>\n",
       "      <td>0.436370</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count        mean        std      min       25%  \\\n",
       "fixed acidity         3155.0    7.221616   1.325297  3.80000   6.40000   \n",
       "volatile acidity      3155.0    0.338929   0.162476  0.08000   0.23000   \n",
       "citric acid           3155.0    0.321569   0.147970  0.00000   0.25000   \n",
       "residual sugar        3155.0    5.155911   4.639632  0.60000   1.80000   \n",
       "chlorides             3155.0    0.056976   0.036802  0.01200   0.03800   \n",
       "free sulfur dioxide   3155.0   30.388590  17.236784  1.00000  17.00000   \n",
       "total sulfur dioxide  3155.0  115.062282  56.706617  6.00000  75.00000   \n",
       "density               3155.0    0.994633   0.003005  0.98711   0.99232   \n",
       "pH                    3155.0    3.223201   0.161272  2.72000   3.11000   \n",
       "sulphates             3155.0    0.534051   0.149149  0.22000   0.43000   \n",
       "alcohol               3155.0   10.504466   1.154654  8.50000   9.50000   \n",
       "quality               3155.0    5.813629   0.701121  5.00000   5.00000   \n",
       "is_red                3155.0    0.255784   0.436370  0.00000   0.00000   \n",
       "\n",
       "                            50%       75%        max  \n",
       "fixed acidity           7.00000    7.7000   15.60000  \n",
       "volatile acidity        0.29000    0.4000    1.24000  \n",
       "citric acid             0.31000    0.4000    1.66000  \n",
       "residual sugar          2.80000    7.6500   65.80000  \n",
       "chlorides               0.04700    0.0660    0.61100  \n",
       "free sulfur dioxide    28.00000   41.0000  131.00000  \n",
       "total sulfur dioxide  117.00000  156.0000  344.00000  \n",
       "density                 0.99481    0.9968    1.03898  \n",
       "pH                      3.21000    3.3300    4.01000  \n",
       "sulphates               0.51000    0.6000    1.95000  \n",
       "alcohol                10.30000   11.3000   14.00000  \n",
       "quality                 6.00000    6.0000    7.00000  \n",
       "is_red                  0.00000    1.0000    1.00000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGPvt9jir_HC"
   },
   "source": [
    "### Get the labels (TODO)\n",
    "\n",
    "The features and labels are currently in the same dataframe.\n",
    "- You will want to store the label columns `is_red` and `quality` separately from the feature columns.  \n",
    "- The following function, `format_output`, gets these two columns from the dataframe (it's given to you).\n",
    "- `format_output` also formats the data into numpy arrays. \n",
    "- Please use the `format_output` and apply it to the `train`, `val` and `test` sets to get dataframes for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_fs14XQqZVP"
   },
   "outputs": [],
   "source": [
    "def format_output(data):\n",
    "    is_red = data.pop('is_red')\n",
    "    is_red = np.array(is_red)\n",
    "    quality = data.pop('quality')\n",
    "    quality = np.array(quality)\n",
    "    return (quality, is_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality', 'is_red'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "8L3ZZe1fQicm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a86809e54895a816434c48dc903f55d",
     "grade": false,
     "grade_id": "cell-5c30fa2c2a354b0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# format the output of the train set\n",
    "train_Y = format_output(train)\n",
    "\n",
    "# format the output of the val set\n",
    "val_Y = format_output(val)\n",
    "    \n",
    "# format the output of the test set\n",
    "test_Y = format_output(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 6, 5, ..., 6, 5, 5], dtype=int64),\n",
       " array([1, 0, 0, ..., 1, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "359cabbafaed14ec9bbc1e57a7b6f32c",
     "grade": true,
     "grade_id": "cell-4977d8befb80f56b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_format_output(df, train_Y, val_Y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_format_output(df, train_Y, val_Y, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that after you get the labels, the `train`, `val` and `test` dataframes no longer contain the label columns, and contain just the feature columns.\n",
    "- This is because you used `.pop` in the `format_output` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEdbrruAsN1D"
   },
   "source": [
    "### Normalize the data (TODO)\n",
    "\n",
    "Next, you can normalize the data, x, using the formula:\n",
    "$$x_{norm} = \\frac{x - \\mu}{\\sigma}$$\n",
    "- The `norm` function is defined for you.\n",
    "- Please apply the `norm` function to normalize the dataframes that contains the feature columns of `train`, `val` and `test` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWiZPAHCLjUs"
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "JEaOi2I2Lk69",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bc0cdcb563d192f271067aa3373ff32",
     "grade": false,
     "grade_id": "cell-d8416d975c371095",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# normalize the train set\n",
    "norm_train_X = norm(train)\n",
    "    \n",
    "# normalize the val set\n",
    "norm_val_X = norm(val)\n",
    "    \n",
    "# normalize the test set\n",
    "norm_test_X = norm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f567db45bf40191601780379cc100b8",
     "grade": true,
     "grade_id": "cell-97fad979d157529b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_norm(norm_train_X, norm_val_X, norm_test_X, train, val, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All public tests passed\n"
     ]
    }
   ],
   "source": [
    "utils11.test_norm(norm_train_X, norm_val_X, norm_test_X, train, val, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzykDwQhsaPO"
   },
   "source": [
    "## Define the Model (TODO)\n",
    "\n",
    "Define the model using the functional API. The base model will be 2 `Dense` layers of 128 neurons each, and have the `'relu'` activation.\n",
    "- Check out the documentation for [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Rhcns3oTFkM6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b031247e569526552bf13a034a1c07",
     "grade": false,
     "grade_id": "cell-73fceedad1fe351c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def base_model(inputs):\n",
    "    \n",
    "    # connect a Dense layer with 128 neurons and a relu activation\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='base_dense_1')(inputs)\n",
    "    \n",
    "    # connect another Dense layer with 128 neurons and a relu activation\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='base_dense_2')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9255924b3def80f679616e4c851a43e1",
     "grade": true,
     "grade_id": "cell-54f742a133353d75",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_type_check: Return type is incorrect. Please check implementation.\n",
      "Expected: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Result: <class 'keras.engine.keras_tensor.KerasTensor'>\n",
      "Please open utils.py if you want to see the unit test here.\n",
      "\n",
      "\u001b[92m 5  Tests passed\n",
      "\u001b[91m 1  Tests failed\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Output layer type is incorrect. Please check implementation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [129]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils11\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\python projects\\Deep learning Tensorflow-coursera\\Added to git\\utils11.py:259\u001b[0m, in \u001b[0;36mtest_base_model\u001b[1;34m(base_model)\u001b[0m\n\u001b[0;32m    218\u001b[0m test_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mtest_inputs, outputs\u001b[38;5;241m=\u001b[39mtest_output)\n\u001b[0;32m    220\u001b[0m test_cases \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    221\u001b[0m     {\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_type_check\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m     },\n\u001b[0;32m    257\u001b[0m ]\n\u001b[1;32m--> 259\u001b[0m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\python projects\\Deep learning Tensorflow-coursera\\Added to git\\utils11.py:27\u001b[0m, in \u001b[0;36mtest_loop\u001b[1;34m(test_cases)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92m\u001b[39m\u001b[38;5;124m'\u001b[39m, success,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Tests passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91m\u001b[39m\u001b[38;5;124m'\u001b[39m, fails, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Tests failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(test_case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_message\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mException\u001b[0m: Output layer type is incorrect. Please check implementation."
     ]
    }
   ],
   "source": [
    "utils11.test_base_model(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xem_fcVws6Kz"
   },
   "source": [
    "# Define output layers of the model\n",
    "\n",
    "You will add output layers to the base model. \n",
    "- The model will need two outputs.\n",
    "\n",
    "One output layer will predict wine quality, which is a numeric value.\n",
    "- Define a `Dense` layer with 1 neuron.\n",
    "- Since this is a regression output, the activation can be left as its default value `None`.\n",
    "\n",
    "The other output layer will predict the wine type, which is either red `1` or not red `0` (white).\n",
    "- Define a `Dense` layer with 1 neuron.\n",
    "- Since there are two possible categories, you can use a sigmoid activation for binary classification.\n",
    "\n",
    "Define the `Model`\n",
    "- Define the `Model` object, and set the following parameters:\n",
    "  - `inputs`: pass in the inputs to the model as a list.\n",
    "  - `outputs`: pass in a list of the outputs that you just defined: wine quality, then wine type.\n",
    "  - **Note**: please list the wine quality before wine type in the outputs, as this will affect the calculated loss if you choose the other order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "n5UGF8PMVLPt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76d35b90d20cdcbb22986cd8211057de",
     "grade": false,
     "grade_id": "cell-19e285f482f021fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "def final_model(inputs):\n",
    "    \n",
    "    # get the base model\n",
    "    x = base_model(inputs)\n",
    "\n",
    "    # connect the output Dense layer for regression\n",
    "    wine_quality = Dense(units='1', name='wine_quality')(x)\n",
    "\n",
    "    # connect the output Dense layer for classification. this will use a sigmoid activation.\n",
    "    wine_type = Dense(units='1', activation='sigmoid', name='wine_type')(x)\n",
    "\n",
    "    # define the model using the input and output layers\n",
    "    model = Model(inputs=inputs, outputs=[wine_quality, wine_type])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89cbf89d8ab5e2e59ecf7f63f517520a",
     "grade": true,
     "grade_id": "cell-40d050f855c817d1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mtest_final_model(final_model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils.test_final_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_type_check: Return type is incorrect. Please check implementation.\n",
      "Expected: <class 'keras.engine.training.Model'>\n",
      "Result: <class 'keras.engine.functional.Functional'>\n",
      "Please open utils.py if you want to see the unit test here.\n",
      "\n",
      "\u001b[92m 1  Tests passed\n",
      "\u001b[91m 1  Tests failed\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "wine_quality layer has an incorrect activation. Please check implementation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils11\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_final_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\python projects\\Deep learning Tensorflow-coursera\\Added to git\\utils11.py:281\u001b[0m, in \u001b[0;36mtest_final_model\u001b[1;34m(final_model)\u001b[0m\n\u001b[0;32m    264\u001b[0m test_output \u001b[38;5;241m=\u001b[39m final_model(test_inputs)\n\u001b[0;32m    266\u001b[0m test_cases \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    267\u001b[0m     {\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_type_check\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m     },\n\u001b[0;32m    279\u001b[0m ]\n\u001b[1;32m--> 281\u001b[0m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\python projects\\Deep learning Tensorflow-coursera\\Added to git\\utils11.py:27\u001b[0m, in \u001b[0;36mtest_loop\u001b[1;34m(test_cases)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92m\u001b[39m\u001b[38;5;124m'\u001b[39m, success,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Tests passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91m\u001b[39m\u001b[38;5;124m'\u001b[39m, fails, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Tests failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(test_case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_message\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mException\u001b[0m: wine_quality layer has an incorrect activation. Please check implementation."
     ]
    }
   ],
   "source": [
    "utils11.test_final_model(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5R0BMTsltZyu"
   },
   "source": [
    "## Compiling the Model\n",
    "\n",
    "Next, compile the model. When setting the loss parameter of `model.compile`, you're setting the loss for each of the two outputs (wine quality and wine type).\n",
    "\n",
    "To set more than one loss, use a dictionary of key-value pairs.\n",
    "- You can look at the docs for the losses [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses#functions).\n",
    "    - **Note**: For the desired spelling, please look at the \"Functions\" section of the documentation and not the \"classes\" section on that same page.\n",
    "- wine_type: Since you will be performing binary classification on wine type, you should use the binary crossentropy loss function for it.  Please pass this in as a string.  \n",
    "  - **Hint**, this should be all lowercase.  In the documentation, you'll see this under the \"Functions\" section, not the \"Classes\" section.\n",
    "- wine_quality: since this is a regression output, use the mean squared error.  Please pass it in as a string, all lowercase.\n",
    "  - **Hint**: You may notice that there are two aliases for mean squared error.  Please use the shorter name.\n",
    "\n",
    "\n",
    "You will also set the metric for each of the two outputs.  Again, to set metrics for two or more outputs, use a dictionary with key value pairs.\n",
    "- The metrics documentation is linked [here](https://www.tensorflow.org/api_docs/python/tf/keras/metrics).\n",
    "- For the wine type, please set it to accuracy as a string, all lowercase.\n",
    "- For wine quality, please use the root mean squared error.  Instead of a string, you'll set it to an instance of the class [RootMeanSquaredError](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RootMeanSquaredError), which belongs to the tf.keras.metrics module.\n",
    "\n",
    "**Note**: If you see the error message \n",
    ">Exception: wine quality loss function is incorrect.\n",
    "\n",
    "- Please also check your other losses and metrics, as the error may be caused by the other three key-value pairs and not the wine quality loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "LK11duUbUjmh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22f45067ca69eb2ccadb43874dbcc27b",
     "grade": false,
     "grade_id": "cell-81afdc4dcca51d5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(11,))\n",
    "rms = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model = final_model(inputs)\n",
    "\n",
    "model.compile(optimizer=rms, \n",
    "              loss = {'wine_type' : 'binary_crossentropy',\n",
    "                      'wine_quality' : 'mean_squared_error'\n",
    "                     },\n",
    "              metrics = {'wine_type' : 'accuracy',\n",
    "                         'wine_quality': tf.keras.metrics.RootMeanSquaredError()\n",
    "                       }\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88e02238ea5e456ff65e835cc8158054",
     "grade": true,
     "grade_id": "cell-2eeeba02391c4632",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "utils.test_model_compile(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90MpAMpWuKm-"
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "Fit the model to the training inputs and outputs. \n",
    "- Check the documentation for [model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\n",
    "- Remember to use the normalized training set as inputs. \n",
    "- For the validation data, please use the normalized validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "_eiZkle4XwiY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca7664be03bfd6fd3651ae44d17b793",
     "grade": false,
     "grade_id": "cell-0bb56262896f6680",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_16\" is incompatible with the layer: expected shape=(None, 11), found shape=(None, 13)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m## You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_train_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnorm_val_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filew26z4myy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\pooya\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_16\" is incompatible with the layer: expected shape=(None, 11), found shape=(None, 13)\n"
     ]
    }
   ],
   "source": [
    "## Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "## You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(norm_train_X, train_Y,\n",
    "                    epochs = 180, validation_data=(norm_val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fadad8896eda9c8c2115970724b15508",
     "grade": true,
     "grade_id": "cell-eb4d5b41bef8f0ab",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "utils.test_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CubF2J2gSf6q"
   },
   "outputs": [],
   "source": [
    "# Gather the training metrics\n",
    "loss, wine_quality_loss, wine_type_loss, wine_quality_rmse, wine_type_accuracy = model.evaluate(x=norm_val_X, y=val_Y)\n",
    "\n",
    "print()\n",
    "print(f'loss: {loss}')\n",
    "print(f'wine_quality_loss: {wine_quality_loss}')\n",
    "print(f'wine_type_loss: {wine_type_loss}')\n",
    "print(f'wine_quality_rmse: {wine_quality_rmse}')\n",
    "print(f'wine_type_accuracy: {wine_type_accuracy}')\n",
    "\n",
    "# EXPECTED VALUES\n",
    "# ~ 0.30 - 0.38\n",
    "# ~ 0.30 - 0.38\n",
    "# ~ 0.018 - 0.030\n",
    "# ~ 0.50 - 0.62\n",
    "# ~ 0.97 - 1.0\n",
    "\n",
    "# Example:\n",
    "#0.3657050132751465\n",
    "#0.3463745415210724\n",
    "#0.019330406561493874\n",
    "#0.5885359048843384\n",
    "#0.9974651336669922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPtTGAP4usnm"
   },
   "source": [
    "## Analyze the Model Performance\n",
    "\n",
    "Note that the model has two outputs. The output at index 0 is quality and index 1 is wine type\n",
    "\n",
    "So, round the quality predictions to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBq9PEeAaW-Y"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(norm_test_X)\n",
    "quality_pred = predictions[0]\n",
    "type_pred = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLhgTR4xTIxj"
   },
   "outputs": [],
   "source": [
    "print(quality_pred[0])\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# 5.6 - 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPi-eYfGTUXi"
   },
   "outputs": [],
   "source": [
    "print(type_pred[0])\n",
    "print(type_pred[944])\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# A number close to zero\n",
    "# A number close to or equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kohk-9C6vt_s"
   },
   "source": [
    "### Plot Utilities\n",
    "\n",
    "We define a few utilities to visualize the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62gEOFUhn6aQ"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metric_name, title, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(history.history[metric_name],color='blue',label=metric_name)\n",
    "    plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rfgSx7uz5dj"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title='', labels=[0,1]):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "          plt.text(j, i, format(cm[i, j], fmt),\n",
    "                  horizontalalignment=\"center\",\n",
    "                  color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfVLIqi017Vf"
   },
   "outputs": [],
   "source": [
    "def plot_diff(y_true, y_pred, title = '' ):\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.plot([-100, 100], [-100, 100])\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sd1jdFbwE0I"
   },
   "source": [
    "### Plots for Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3MwZ5J1pOfj"
   },
   "outputs": [],
   "source": [
    "plot_metrics('wine_quality_root_mean_squared_error', 'RMSE', ylim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIAxEezCppnd"
   },
   "outputs": [],
   "source": [
    "plot_metrics('wine_type_loss', 'Wine Type Loss', ylim=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYV9AOAMwI9p"
   },
   "source": [
    "### Plots for Confusion Matrix\n",
    "\n",
    "Plot the confusion matrices for wine type. You can see that the model performs well for prediction of wine type from the confusion matrix and the loss metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3hvTYxIaf3n"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_Y[1], np.round(type_pred), title='Wine Type', labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GW91ym8P2I5y"
   },
   "outputs": [],
   "source": [
    "scatter_plot = plot_diff(test_Y[0], quality_pred, title='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "exercise-answer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
